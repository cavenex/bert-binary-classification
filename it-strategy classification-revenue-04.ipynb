{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:40.139648Z",
     "start_time": "2020-08-09T19:11:36.224641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:40.653357Z",
     "start_time": "2020-08-09T19:11:40.142620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-DGXS-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:40.670979Z",
     "start_time": "2020-08-09T19:11:40.655392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef set_seed(seed_value=42):\\n    random.seed(seed_value)\\n    np.random.seed(seed_value)\\n    torch.manual_seed(seed_value)\\n    torch.cuda.manual_seed_all(seed_value)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\"\"\"\n",
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:41.032063Z",
     "start_time": "2020-08-09T19:11:40.676205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0809 19:11:40.941958 140636640298752 file_utils.py:41] PyTorch version 1.2.0 available.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:41.049446Z",
     "start_time": "2020-08-09T19:11:41.035250Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('it-annotation-1000-revenue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:41.063632Z",
     "start_time": "2020-08-09T19:11:41.051334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Regarding our second action, the strategic rev...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Depreciation and amortization decreased $10.5 ...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Our competitors compete with us in many ways, ...</td>\n",
       "      <td>revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>In particular, depreciation and amortization c...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.                                               Data    Label\n",
       "0    1  Regarding our second action, the strategic rev...  neither\n",
       "1    2  Depreciation and amortization decreased $10.5 ...  neither\n",
       "2    3                             Information Technology  neither\n",
       "3    4  Our competitors compete with us in many ways, ...  revenue\n",
       "4    5  In particular, depreciation and amortization c...  neither"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:41.070074Z",
     "start_time": "2020-08-09T19:11:41.065456Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['Data','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:41.085006Z",
     "start_time": "2020-08-09T19:11:41.073806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neither    935\n",
       "revenue     65\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:41.196938Z",
     "start_time": "2020-08-09T19:11:41.087261Z"
    }
   },
   "outputs": [],
   "source": [
    "encode_dict = {}\n",
    "\n",
    "def encode_cat(x):\n",
    "    if x not in encode_dict.keys():\n",
    "        encode_dict[x]=len(encode_dict)\n",
    "    return encode_dict[x]\n",
    "\n",
    "df['encode_cat'] = df['Label'].apply(lambda x: encode_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:41.212702Z",
     "start_time": "2020-08-09T19:11:41.199328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEMENT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>ENCODE_CAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regarding our second action, the strategic rev...</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Depreciation and amortization decreased $10.5 ...</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our competitors compete with us in many ways, ...</td>\n",
       "      <td>revenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In particular, depreciation and amortization c...</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           STATEMENT    LABEL  ENCODE_CAT\n",
       "0  Regarding our second action, the strategic rev...  neither           0\n",
       "1  Depreciation and amortization decreased $10.5 ...  neither           0\n",
       "2                             Information Technology  neither           0\n",
       "3  Our competitors compete with us in many ways, ...  revenue           1\n",
       "4  In particular, depreciation and amortization c...  neither           0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['STATEMENT', 'LABEL', 'ENCODE_CAT']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:41.218797Z",
     "start_time": "2020-08-09T19:11:41.214882Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = {0: \"neither\", 1: \"revenue\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:42.168911Z",
     "start_time": "2020-08-09T19:11:41.221265Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0809 19:11:42.120397 140636640298752 tokenization_utils.py:501] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-05\n",
    "\n",
    "# Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "D_in, H, D_out = 768, 50, 2\n",
    "dropout_rate = 0.3\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:42.184352Z",
     "start_time": "2020-08-09T19:11:42.173542Z"
    }
   },
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.STATEMENT[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.ENCODE_CAT[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:42.199775Z",
     "start_time": "2020-08-09T19:11:42.187403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (1000, 3)\n",
      "TRAIN Dataset: (750, 3)\n",
      "TEST Dataset: (250, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.75\n",
    "train_dataset=df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:42.212218Z",
     "start_time": "2020-08-09T19:11:42.203605Z"
    }
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params, drop_last=True)\n",
    "testing_loader = DataLoader(testing_set, **test_params, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:42.224925Z",
     "start_time": "2020-08-09T19:11:42.214712Z"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Linear(D_in, H)        \n",
    "        self.l3 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l4 = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        output_1 = self.l1(ids, mask)\n",
    "        output_2 = self.l2(output_1[0][:,0,:])\n",
    "        output_3 = self.l3(output_2)\n",
    "        output = self.l4(output_3)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:53.264178Z",
     "start_time": "2020-08-09T19:11:42.227379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0809 19:11:43.095481 140636640298752 configuration_utils.py:256] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "I0809 19:11:43.097028 140636640298752 configuration_utils.py:292] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0809 19:11:43.955685 140636640298752 modeling_utils.py:461] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Linear(in_features=768, out_features=50, bias=True)\n",
       "  (l3): Dropout(p=0.3, inplace=False)\n",
       "  (l4): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClass()\n",
    "# model.load_state_dict(torch.load('it-strategy-classification_revenue_01.pt')) # if loading from saved state\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:53.272401Z",
     "start_time": "2020-08-09T19:11:53.266295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:11:53.283465Z",
     "start_time": "2020-08-09T19:11:53.274617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the training function \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        # print(outputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _%5000==0:\n",
    "            print(\"Epoch: {}\".format(epoch),\", Loss:  {}\".format(loss.item()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:17:36.628788Z",
     "start_time": "2020-08-09T19:11:53.285853Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , Loss:  0.768957257270813\n",
      "Epoch: 1 , Loss:  0.08177986741065979\n",
      "Epoch: 2 , Loss:  0.0352206826210022\n",
      "Epoch: 3 , Loss:  0.0045204758644104\n",
      "Epoch: 4 , Loss:  0.0058994293212890625\n",
      "343.338045835495\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:17:36.639856Z",
     "start_time": "2020-08-09T19:17:36.631218Z"
    }
   },
   "outputs": [],
   "source": [
    "def bert_predict(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets = []; fin_outputs_prob = [] \n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask).squeeze()\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs_prob.extend(torch.nn.functional.softmax(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_targets, fin_outputs_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:17:44.671670Z",
     "start_time": "2020-08-09T19:17:36.642086Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "targets, probs = bert_predict(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:22:51.123127Z",
     "start_time": "2020-08-09T19:22:51.104097Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.30      0.44        20\n",
      "           0       0.94      1.00      0.97       230\n",
      "\n",
      "    accuracy                           0.94       250\n",
      "   macro avg       0.90      0.65      0.71       250\n",
      "weighted avg       0.94      0.94      0.93       250\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  6  14]\n",
      " [  1 229]]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the probabilities\n",
    "threshold = 0.4\n",
    "probs = np.array(probs)\n",
    "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
    "\n",
    "print(metrics.classification_report(targets, preds,labels=[1,0]))\n",
    "print(\"Confusion Matrix:\", '\\n',metrics.confusion_matrix(targets,preds,labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:17:44.694865Z",
     "start_time": "2020-08-09T19:17:44.690107Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(targets, probs[:,1],pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:19:37.143018Z",
     "start_time": "2020-08-09T19:19:36.916729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe48122ba20>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:17:44.955949Z",
     "start_time": "2020-08-09T19:17:44.953246Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'it-strategy-classification_revenue_01.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
